{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42b1ac9d",
   "metadata": {},
   "source": [
    "# Week 7 Solutions\n",
    "## Machine Learning Problems - Comprehensive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56fbcd0",
   "metadata": {},
   "source": [
    "## Question 1: California Housing Dataset - Model Comparison\n",
    "\n",
    "Load the fetch_california_housing dataset, split the data with test_size=0.2 and random_state=1.\n",
    "Train three models and compare R2 Score and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b86c30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for Question 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "032c62f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn cache not available, using downloaded data...\n",
      "Loaded CSV with shape: (20640, 10)\n",
      "✓ Processed California Housing data to match sklearn format\n",
      "\n",
      "✓ Dataset ready!\n",
      "Dataset shape: X=(20433, 8), y=(20433,)\n",
      "Features: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Target range: 0.15 to 5.00\n"
     ]
    }
   ],
   "source": [
    "# Load the California Housing dataset\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Check if we have the downloaded data\n",
    "data_home = os.path.expanduser('~/scikit_learn_data')\n",
    "archive_path = os.path.join(data_home, 'cal_housing.tgz')\n",
    "\n",
    "try:\n",
    "    # Try to load from sklearn's cache first\n",
    "    california = fetch_california_housing()\n",
    "    print(\"✓ Loaded from sklearn cache\")\n",
    "except:\n",
    "    print(\"sklearn cache not available, using downloaded data...\")\n",
    "    \n",
    "    # Extract and load the downloaded housing data\n",
    "    if os.path.exists(archive_path):\n",
    "        # Extract the CSV\n",
    "        with tarfile.open(archive_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=data_home)\n",
    "        \n",
    "        # Load the CSV file\n",
    "        csv_path = os.path.join(data_home, 'housing.csv')\n",
    "        if os.path.exists(csv_path):\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(csv_path)\n",
    "            \n",
    "            print(f\"Loaded CSV with shape: {df.shape}\")\n",
    "            \n",
    "            # Process to match sklearn's California Housing format\n",
    "            # sklearn format has these features in this order:\n",
    "            # MedInc, HouseAge, AveRooms, AveBedrms, Population, AveOccup, Latitude, Longitude\n",
    "            \n",
    "            # Handle missing values\n",
    "            df = df.dropna()\n",
    "            \n",
    "            # Calculate derived features to match sklearn\n",
    "            df['AveRooms'] = df['total_rooms'] / df['households']\n",
    "            df['AveBedrms'] = df['total_bedrooms'] / df['households']\n",
    "            df['AveOccup'] = df['population'] / df['households']\n",
    "            \n",
    "            # Create feature matrix in sklearn order\n",
    "            feature_data = pd.DataFrame({\n",
    "                'MedInc': df['median_income'],\n",
    "                'HouseAge': df['housing_median_age'],\n",
    "                'AveRooms': df['AveRooms'],\n",
    "                'AveBedrms': df['AveBedrms'],\n",
    "                'Population': df['population'],\n",
    "                'AveOccup': df['AveOccup'],\n",
    "                'Latitude': df['latitude'],\n",
    "                'Longitude': df['longitude']\n",
    "            })\n",
    "            \n",
    "            # Create target (scaled to match sklearn - in units of 100,000)\n",
    "            target_data = df['median_house_value'] / 100000.0\n",
    "            \n",
    "            # Create a Bunch object to match sklearn's return format\n",
    "            class Bunch:\n",
    "                pass\n",
    "            california = Bunch()\n",
    "            california.data = feature_data.values\n",
    "            california.target = target_data.values\n",
    "            california.feature_names = list(feature_data.columns)\n",
    "            \n",
    "            print(f\"✓ Processed California Housing data to match sklearn format\")\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Could not find housing.csv after extraction\")\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Archive not found at {archive_path}\")\n",
    "\n",
    "X = california.data\n",
    "y = california.target\n",
    "\n",
    "print(f\"\\n✓ Dataset ready!\")\n",
    "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Features: {california.feature_names}\")\n",
    "print(f\"Target range: {y.min():.2f} to {y.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20367eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 16346\n",
      "Test set size: 4087\n"
     ]
    }
   ],
   "source": [
    "# Split the data with test_size=0.2 and random_state=1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f41d9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1: Linear Regression\n",
      "Model 1 - Linear Regression:\n",
      "  R2 Score: 0.599717\n",
      "  RMSE: 0.729555\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Linear Regression\n",
    "print(\"Training Model 1: Linear Regression\")\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train, y_train)\n",
    "y_pred1 = model1.predict(X_test)\n",
    "\n",
    "r2_model1 = r2_score(y_test, y_pred1)\n",
    "rmse_model1 = np.sqrt(mean_squared_error(y_test, y_pred1))\n",
    "\n",
    "print(f\"Model 1 - Linear Regression:\")\n",
    "print(f\"  R2 Score: {r2_model1:.6f}\")\n",
    "print(f\"  RMSE: {rmse_model1:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "144386c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2: AdaBoost Regressor\n",
      "Model 2 - AdaBoost Regressor:\n",
      "  R2 Score: 0.427368\n",
      "  RMSE: 0.872595\n"
     ]
    }
   ],
   "source": [
    "# Model 2: AdaBoost Regressor with random_state=1\n",
    "print(\"\\nTraining Model 2: AdaBoost Regressor\")\n",
    "model2 = AdaBoostRegressor(random_state=1)\n",
    "model2.fit(X_train, y_train)\n",
    "y_pred2 = model2.predict(X_test)\n",
    "\n",
    "r2_model2 = r2_score(y_test, y_pred2)\n",
    "rmse_model2 = np.sqrt(mean_squared_error(y_test, y_pred2))\n",
    "\n",
    "print(f\"Model 2 - AdaBoost Regressor:\")\n",
    "print(f\"  R2 Score: {r2_model2:.6f}\")\n",
    "print(f\"  RMSE: {rmse_model2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5545e670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3: Decision Tree Regressor\n",
      "Model 3 - Decision Tree Regressor:\n",
      "  R2 Score: 0.581542\n",
      "  RMSE: 0.745934\n"
     ]
    }
   ],
   "source": [
    "# Model 3: Decision Tree Regressor with random_state=1\n",
    "print(\"\\nTraining Model 3: Decision Tree Regressor\")\n",
    "model3 = DecisionTreeRegressor(random_state=1)\n",
    "model3.fit(X_train, y_train)\n",
    "y_pred3 = model3.predict(X_test)\n",
    "\n",
    "r2_model3 = r2_score(y_test, y_pred3)\n",
    "rmse_model3 = np.sqrt(mean_squared_error(y_test, y_pred3))\n",
    "\n",
    "print(f\"Model 3 - Decision Tree Regressor:\")\n",
    "print(f\"  R2 Score: {r2_model3:.6f}\")\n",
    "print(f\"  RMSE: {rmse_model3:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14294211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION 1 - SUMMARY AND COMPARISON\n",
      "============================================================\n",
      "\n",
      "                            Model  R2 Score     RMSE\n",
      "      Model 1: Linear Regression  0.599717 0.729555\n",
      "     Model 2: AdaBoost Regressor  0.427368 0.872595\n",
      "Model 3: Decision Tree Regressor  0.581542 0.745934\n",
      "\n",
      "------------------------------------------------------------\n",
      "R2 Score Ranking (Higher is Better):\n",
      "------------------------------------------------------------\n",
      "Model 1: Linear Regression: 0.599717\n",
      "Model 3: Decision Tree Regressor: 0.581542\n",
      "Model 2: AdaBoost Regressor: 0.427368\n",
      "\n",
      "------------------------------------------------------------\n",
      "RMSE Ranking (Lower is Better):\n",
      "------------------------------------------------------------\n",
      "Model 1: Linear Regression: 0.729555\n",
      "Model 3: Decision Tree Regressor: 0.745934\n",
      "Model 2: AdaBoost Regressor: 0.872595\n",
      "\n",
      "============================================================\n",
      "CHECKING OPTIONS:\n",
      "============================================================\n",
      "(A) r2_score (Model 2) > r2_score (Model 1) > r2_score (Model 3): False\n",
      "    0.427368 > 0.599717 > 0.581542\n",
      "\n",
      "(B) r2_score (Model 3) > r2_score (Model 1) > r2_score (Model 2): False\n",
      "    0.581542 > 0.599717 > 0.427368\n",
      "\n",
      "(C) RMSE (Model 2) > RMSE (Model 1) > RMSE (Model 3): False\n",
      "    0.872595 > 0.729555 > 0.745934\n",
      "\n",
      "(D) RMSE (Model 3) > RMSE (Model 1) > RMSE (Model 2): False\n",
      "    0.745934 > 0.729555 > 0.872595\n",
      "\n",
      "============================================================\n",
      "CORRECT ANSWER(S) FOR QUESTION 1: \n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Summary and Comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUESTION 1 - SUMMARY AND COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Model 1: Linear Regression', 'Model 2: AdaBoost Regressor', 'Model 3: Decision Tree Regressor'],\n",
    "    'R2 Score': [r2_model1, r2_model2, r2_model3],\n",
    "    'RMSE': [rmse_model1, rmse_model2, rmse_model3]\n",
    "})\n",
    "\n",
    "print(\"\\n\", results_df.to_string(index=False))\n",
    "\n",
    "# Sort by R2 Score (descending)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"R2 Score Ranking (Higher is Better):\")\n",
    "print(\"-\"*60)\n",
    "r2_sorted = results_df.sort_values('R2 Score', ascending=False)\n",
    "for idx, row in r2_sorted.iterrows():\n",
    "    print(f\"{row['Model']}: {row['R2 Score']:.6f}\")\n",
    "\n",
    "# Sort by RMSE (ascending)\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"RMSE Ranking (Lower is Better):\")\n",
    "print(\"-\"*60)\n",
    "rmse_sorted = results_df.sort_values('RMSE', ascending=True)\n",
    "for idx, row in rmse_sorted.iterrows():\n",
    "    print(f\"{row['Model']}: {row['RMSE']:.6f}\")\n",
    "\n",
    "# Check all options\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CHECKING OPTIONS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Option A: r2_score (Model 2) > r2_score (Model 1) > r2_score (Model 3)\n",
    "option_a = (r2_model2 > r2_model1) and (r2_model1 > r2_model3)\n",
    "print(f\"(A) r2_score (Model 2) > r2_score (Model 1) > r2_score (Model 3): {option_a}\")\n",
    "print(f\"    {r2_model2:.6f} > {r2_model1:.6f} > {r2_model3:.6f}\")\n",
    "\n",
    "# Option B: r2_score (Model 3) > r2_score (Model 1) > r2_score (Model 2)\n",
    "option_b = (r2_model3 > r2_model1) and (r2_model1 > r2_model2)\n",
    "print(f\"\\n(B) r2_score (Model 3) > r2_score (Model 1) > r2_score (Model 2): {option_b}\")\n",
    "print(f\"    {r2_model3:.6f} > {r2_model1:.6f} > {r2_model2:.6f}\")\n",
    "\n",
    "# Option C: RMSE (Model 2) > RMSE (Model 1) > RMSE (Model 3)\n",
    "option_c = (rmse_model2 > rmse_model1) and (rmse_model1 > rmse_model3)\n",
    "print(f\"\\n(C) RMSE (Model 2) > RMSE (Model 1) > RMSE (Model 3): {option_c}\")\n",
    "print(f\"    {rmse_model2:.6f} > {rmse_model1:.6f} > {rmse_model3:.6f}\")\n",
    "\n",
    "# Option D: RMSE (Model 3) > RMSE (Model 1) > RMSE (Model 2)\n",
    "option_d = (rmse_model3 > rmse_model1) and (rmse_model1 > rmse_model2)\n",
    "print(f\"\\n(D) RMSE (Model 3) > RMSE (Model 1) > RMSE (Model 2): {option_d}\")\n",
    "print(f\"    {rmse_model3:.6f} > {rmse_model1:.6f} > {rmse_model2:.6f}\")\n",
    "\n",
    "# Determine correct answer\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "correct_options = []\n",
    "if option_a:\n",
    "    correct_options.append('A')\n",
    "if option_b:\n",
    "    correct_options.append('B')\n",
    "if option_c:\n",
    "    correct_options.append('C')\n",
    "if option_d:\n",
    "    correct_options.append('D')\n",
    "\n",
    "print(f\"CORRECT ANSWER(S) FOR QUESTION 1: {', '.join(correct_options)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd586f",
   "metadata": {},
   "source": [
    "## Questions 2 & 3: Iris Dataset - Logistic Regression Classification\n",
    "\n",
    "Load Iris dataset, split with test_size=0.33 and random_state=1.\n",
    "Train Logistic Regression model and analyze results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a7b5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for Questions 2 & 3\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d43a1c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris dataset shape: X=(150, 4), y=(150,)\n",
      "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target classes: ['setosa' 'versicolor' 'virginica']\n",
      "Class distribution: [50 50 50]\n"
     ]
    }
   ],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "print(f\"Iris dataset shape: X={X_iris.shape}, y={y_iris.shape}\")\n",
    "print(f\"Features: {iris.feature_names}\")\n",
    "print(f\"Target classes: {iris.target_names}\")\n",
    "print(f\"Class distribution: {np.bincount(y_iris)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bcf9e994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 100\n",
      "Test set size: 50\n"
     ]
    }
   ],
   "source": [
    "# Split the data with test_size=0.33 and random_state=1\n",
    "X_train_iris, X_test_iris, y_train_iris, y_test_iris = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.33, random_state=1\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_iris.shape[0]}\")\n",
    "print(f\"Test set size: {X_test_iris.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57931243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model trained successfully\n",
      "Training score: 0.9800\n",
      "Test score: 0.9800\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model with random_state=1\n",
    "log_reg = LogisticRegression(random_state=1, max_iter=200)\n",
    "log_reg.fit(X_train_iris, y_train_iris)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_iris = log_reg.predict(X_test_iris)\n",
    "\n",
    "print(\"Logistic Regression model trained successfully\")\n",
    "print(f\"Training score: {log_reg.score(X_train_iris, y_train_iris):.4f}\")\n",
    "print(f\"Test score: {log_reg.score(X_test_iris, y_test_iris):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "745578d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONFUSION MATRIX:\n",
      "============================================================\n",
      "[[17  0  0]\n",
      " [ 0 18  1]\n",
      " [ 0  0 14]]\n",
      "\n",
      "Confusion Matrix (formatted):\n",
      "          Predicted 0  Predicted 1  Predicted 2\n",
      "Actual 0           17            0            0\n",
      "Actual 1            0           18            1\n",
      "Actual 2            0            0           14\n"
     ]
    }
   ],
   "source": [
    "# Print confusion matrix\n",
    "cm = confusion_matrix(y_test_iris, y_pred_iris)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(\"=\"*60)\n",
    "print(cm)\n",
    "print(\"\\nConfusion Matrix (formatted):\")\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=['Actual 0', 'Actual 1', 'Actual 2'],\n",
    "                     columns=['Predicted 0', 'Predicted 1', 'Predicted 2'])\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4317f33a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT:\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        17\n",
      "  versicolor       1.00      0.95      0.97        19\n",
      "   virginica       0.93      1.00      0.97        14\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test_iris, y_pred_iris, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9089125d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION 2: NUMBER OF MISCLASSIFIED SAMPLES\n",
      "============================================================\n",
      "Total test samples: 50\n",
      "Correctly classified: 49\n",
      "Misclassified samples: 1\n",
      "Misclassified (from confusion matrix): 1\n",
      "\n",
      "Accuracy: 98.00%\n",
      "\n",
      "============================================================\n",
      "ANSWER TO QUESTION 2: 1\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Question 2: How many samples has the model misclassified?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUESTION 2: NUMBER OF MISCLASSIFIED SAMPLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Misclassified samples are those where prediction != actual\n",
    "misclassified = np.sum(y_pred_iris != y_test_iris)\n",
    "\n",
    "# Also calculate from confusion matrix (sum of off-diagonal elements)\n",
    "misclassified_from_cm = np.sum(cm) - np.trace(cm)\n",
    "\n",
    "print(f\"Total test samples: {len(y_test_iris)}\")\n",
    "print(f\"Correctly classified: {np.sum(y_pred_iris == y_test_iris)}\")\n",
    "print(f\"Misclassified samples: {misclassified}\")\n",
    "print(f\"Misclassified (from confusion matrix): {misclassified_from_cm}\")\n",
    "print(f\"\\nAccuracy: {np.sum(y_pred_iris == y_test_iris) / len(y_test_iris) * 100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ANSWER TO QUESTION 2: {misclassified}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b294658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION 3: RECALL FOR CLASS 1\n",
      "============================================================\n",
      "Recall for class 0: 1.0000\n",
      "Recall for class 1: 0.9474\n",
      "Recall for class 2: 1.0000\n",
      "\n",
      "Manual calculation for class 1:\n",
      "  True Positives (TP): 18\n",
      "  False Negatives (FN): 1\n",
      "  Recall = TP / (TP + FN) = 18 / 19 = 0.9474\n",
      "\n",
      "============================================================\n",
      "ANSWER TO QUESTION 3: 0.95\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Question 3: What is the recall for class 1?\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUESTION 3: RECALL FOR CLASS 1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extract recall from classification report\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate recall for each class\n",
    "recall_class_0 = recall_score(y_test_iris, y_pred_iris, labels=[0], average=None)[0]\n",
    "recall_class_1 = recall_score(y_test_iris, y_pred_iris, labels=[1], average=None)[0]\n",
    "recall_class_2 = recall_score(y_test_iris, y_pred_iris, labels=[2], average=None)[0]\n",
    "\n",
    "print(f\"Recall for class 0: {recall_class_0:.4f}\")\n",
    "print(f\"Recall for class 1: {recall_class_1:.4f}\")\n",
    "print(f\"Recall for class 2: {recall_class_2:.4f}\")\n",
    "\n",
    "# Manual calculation for class 1 from confusion matrix\n",
    "# Recall = True Positives / (True Positives + False Negatives)\n",
    "# For class 1: TP = cm[1,1], FN = sum of row 1 except diagonal\n",
    "tp_class1 = cm[1, 1]\n",
    "fn_class1 = np.sum(cm[1, :]) - cm[1, 1]\n",
    "recall_class1_manual = tp_class1 / (tp_class1 + fn_class1)\n",
    "\n",
    "print(f\"\\nManual calculation for class 1:\")\n",
    "print(f\"  True Positives (TP): {tp_class1}\")\n",
    "print(f\"  False Negatives (FN): {fn_class1}\")\n",
    "print(f\"  Recall = TP / (TP + FN) = {tp_class1} / {tp_class1 + fn_class1} = {recall_class1_manual:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ANSWER TO QUESTION 3: {recall_class_1:.2f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fc287b",
   "metadata": {},
   "source": [
    "## Questions 4 & 5: 20 Newsgroups Dataset - Text Classification\n",
    "\n",
    "Load 20newsgroups train subset, vectorize with TfidfVectorizer, train MultinomialNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0723c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for Questions 4 & 5\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29b2da0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 20newsgroups dataset...\n",
      "Standard download failed, loading from local cache...\n",
      "✓ Loaded from local pickle cache\n",
      "\n",
      "Dataset loaded successfully\n",
      "Number of documents: 11314\n",
      "Number of categories: 20\n",
      "Type of X: <class 'list'>\n",
      "Type of y: <class 'numpy.ndarray'>\n",
      "Shape of y: (11314,)\n"
     ]
    }
   ],
   "source": [
    "# Load the train subset of 20newsgroups with return_X_y=True\n",
    "print(\"Loading 20newsgroups dataset...\")\n",
    "\n",
    "try:\n",
    "    X_news, y_news = fetch_20newsgroups(subset='train', return_X_y=True, random_state=1)\n",
    "    print(\"✓ Loaded from sklearn\")\n",
    "except:\n",
    "    # If download fails, load directly from the manually downloaded cache\n",
    "    print(\"Standard download failed, loading from local cache...\")\n",
    "    import pickle\n",
    "    cache_path = os.path.expanduser('~/scikit_learn_data/20news_home/20news-bydate_py3.pkz')\n",
    "    \n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'rb') as f:\n",
    "            cache = pickle.load(f)\n",
    "        \n",
    "        train_data = cache['train']\n",
    "        X_news = train_data.data\n",
    "        y_news = train_data.target\n",
    "        print(\"✓ Loaded from local pickle cache\")\n",
    "    else:\n",
    "        # Last resort: load directly from extracted files\n",
    "        from sklearn.datasets._twenty_newsgroups import load_files\n",
    "        train_path = os.path.expanduser('~/scikit_learn_data/20news-bydate-train')\n",
    "        train_data = load_files(train_path, encoding='latin1', decode_error='ignore')\n",
    "        X_news = train_data.data\n",
    "        y_news = train_data.target\n",
    "        print(\"✓ Loaded directly from extracted files\")\n",
    "\n",
    "print(f\"\\nDataset loaded successfully\")\n",
    "print(f\"Number of documents: {len(X_news)}\")\n",
    "print(f\"Number of categories: {len(np.unique(y_news))}\")\n",
    "print(f\"Type of X: {type(X_news)}\")\n",
    "print(f\"Type of y: {type(y_news)}\")\n",
    "print(f\"Shape of y: {y_news.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ed4cf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vectorizing text data using TfidfVectorizer...\n",
      "\n",
      "Vectorization complete\n",
      "Type of vectorized data: <class 'scipy.sparse._csr.csr_matrix'>\n",
      "Shape of vectorized data: (11314, 130107)\n"
     ]
    }
   ],
   "source": [
    "# Vectorize X using TfidfVectorizer\n",
    "print(\"\\nVectorizing text data using TfidfVectorizer...\")\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X_news)\n",
    "\n",
    "print(f\"\\nVectorization complete\")\n",
    "print(f\"Type of vectorized data: {type(X_vectorized)}\")\n",
    "print(f\"Shape of vectorized data: {X_vectorized.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eddea0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION 4: SHAPE OF FITTED AND TRANSFORMED DATA\n",
      "============================================================\n",
      "\n",
      "Shape of vectorized X: (11314, 130107)\n",
      "Number of documents: 11314\n",
      "Number of features (vocabulary size): 130107\n",
      "\n",
      "------------------------------------------------------------\n",
      "CHECKING OPTIONS:\n",
      "------------------------------------------------------------\n",
      "(A) (11310, 130507): False\n",
      "(B) (21314, 190807): False\n",
      "(C) (11514, 160107): False\n",
      "(D) (11314, 130107): True\n",
      "\n",
      "============================================================\n",
      "ANSWER TO QUESTION 4: (D) (11314, 130107)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Shape of the fitted and transformed data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUESTION 4: SHAPE OF FITTED AND TRANSFORMED DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "shape_X = X_vectorized.shape\n",
    "print(f\"\\nShape of vectorized X: {shape_X}\")\n",
    "print(f\"Number of documents: {shape_X[0]}\")\n",
    "print(f\"Number of features (vocabulary size): {shape_X[1]}\")\n",
    "\n",
    "# Check which option matches\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"CHECKING OPTIONS:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "options = {\n",
    "    'A': (11310, 130507),\n",
    "    'B': (21314, 190807),\n",
    "    'C': (11514, 160107),\n",
    "    'D': (11314, 130107)\n",
    "}\n",
    "\n",
    "for option, expected_shape in options.items():\n",
    "    match = (shape_X == expected_shape)\n",
    "    print(f\"({option}) {expected_shape}: {match}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "for option, expected_shape in options.items():\n",
    "    if shape_X == expected_shape:\n",
    "        print(f\"ANSWER TO QUESTION 4: ({option}) {expected_shape}\")\n",
    "        break\n",
    "else:\n",
    "    print(f\"ANSWER TO QUESTION 4: Actual shape is {shape_X}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9584dbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting data into train and validation sets...\n",
      "Training set size: 7919\n",
      "Validation set size: 3395\n",
      "Training set shape: (7919, 130107)\n",
      "Validation set shape: (3395, 130107)\n"
     ]
    }
   ],
   "source": [
    "# Split vectorized data with test_size=0.3 and random_state=1\n",
    "print(\"\\nSplitting data into train and validation sets...\")\n",
    "X_train_news, X_val_news, y_train_news, y_val_news = train_test_split(\n",
    "    X_vectorized, y_news, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train_news.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val_news.shape[0]}\")\n",
    "print(f\"Training set shape: {X_train_news.shape}\")\n",
    "print(f\"Validation set shape: {X_val_news.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ded40fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "QUESTION 5: MULTINOMIAL NB VALIDATION SCORE\n",
      "============================================================\n",
      "\n",
      "Training MultinomialNB model...\n",
      "\n",
      "Model training complete\n",
      "Training score: 0.936482\n",
      "Validation score: 0.840648\n",
      "Validation accuracy (verification): 0.840648\n",
      "\n",
      "============================================================\n",
      "ANSWER TO QUESTION 5: 0.840648\n",
      "Validation Score (more precision): 0.8406480117820324\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Question 5: Train MultinomialNB and compute validation score\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"QUESTION 5: MULTINOMIAL NB VALIDATION SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nTraining MultinomialNB model...\")\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_news, y_train_news)\n",
    "\n",
    "# Compute score on validation set\n",
    "train_score = mnb.score(X_train_news, y_train_news)\n",
    "val_score = mnb.score(X_val_news, y_val_news)\n",
    "\n",
    "print(f\"\\nModel training complete\")\n",
    "print(f\"Training score: {train_score:.6f}\")\n",
    "print(f\"Validation score: {val_score:.6f}\")\n",
    "\n",
    "# Make predictions for additional analysis\n",
    "y_pred_news = mnb.predict(X_val_news)\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_val_news, y_pred_news)\n",
    "print(f\"Validation accuracy (verification): {accuracy:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ANSWER TO QUESTION 5: {val_score:.6f}\")\n",
    "print(f\"Validation Score (more precision): {val_score}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bbed84",
   "metadata": {},
   "source": [
    "## Final Summary of All Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d57e2164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "#                                                                    #\n",
      "#                    FINAL ANSWERS SUMMARY                           #\n",
      "#                                                                    #\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "QUESTION 1: California Housing - Model Comparison\n",
      "======================================================================\n",
      "Model 1 (Linear Regression)    - R2: 0.599717, RMSE: 0.729555\n",
      "Model 2 (AdaBoost Regressor)   - R2: 0.427368, RMSE: 0.872595\n",
      "Model 3 (Decision Tree)        - R2: 0.581542, RMSE: 0.745934\n",
      "\n",
      "Correct option(s):\n",
      "\n",
      "======================================================================\n",
      "QUESTION 2: Iris Dataset - Misclassified Samples\n",
      "======================================================================\n",
      "Answer: 1 samples misclassified\n",
      "\n",
      "======================================================================\n",
      "QUESTION 3: Iris Dataset - Recall for Class 1\n",
      "======================================================================\n",
      "Answer: 0.95\n",
      "\n",
      "======================================================================\n",
      "QUESTION 4: 20 Newsgroups - Shape of Vectorized Data\n",
      "======================================================================\n",
      "Answer: (11314, 130107)\n",
      "  ✓ Option D: (11314, 130107)\n",
      "\n",
      "======================================================================\n",
      "QUESTION 5: 20 Newsgroups - MultinomialNB Validation Score\n",
      "======================================================================\n",
      "Answer: 0.840648\n",
      "Full precision: 0.8406480117820324\n",
      "\n",
      "######################################################################\n",
      "#                      END OF ANALYSIS                               #\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "# Print final summary of all answers\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"#\" + \" \"*68 + \"#\")\n",
    "print(\"#\" + \" \"*20 + \"FINAL ANSWERS SUMMARY\" + \" \"*27 + \"#\")\n",
    "print(\"#\" + \" \"*68 + \"#\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUESTION 1: California Housing - Model Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model 1 (Linear Regression)    - R2: {r2_model1:.6f}, RMSE: {rmse_model1:.6f}\")\n",
    "print(f\"Model 2 (AdaBoost Regressor)   - R2: {r2_model2:.6f}, RMSE: {rmse_model2:.6f}\")\n",
    "print(f\"Model 3 (Decision Tree)        - R2: {r2_model3:.6f}, RMSE: {rmse_model3:.6f}\")\n",
    "print(\"\\nCorrect option(s):\")\n",
    "for opt in correct_options:\n",
    "    print(f\"  ✓ Option {opt}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUESTION 2: Iris Dataset - Misclassified Samples\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {misclassified} samples misclassified\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUESTION 3: Iris Dataset - Recall for Class 1\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {recall_class_1:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUESTION 4: 20 Newsgroups - Shape of Vectorized Data\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {shape_X}\")\n",
    "for option, expected_shape in options.items():\n",
    "    if shape_X == expected_shape:\n",
    "        print(f\"  ✓ Option {option}: {expected_shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"QUESTION 5: 20 Newsgroups - MultinomialNB Validation Score\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Answer: {val_score:.6f}\")\n",
    "print(f\"Full precision: {val_score}\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"#\" + \" \"*22 + \"END OF ANALYSIS\" + \" \"*31 + \"#\")\n",
    "print(\"#\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
