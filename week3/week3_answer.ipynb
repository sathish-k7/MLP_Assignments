{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6220f97",
   "metadata": {},
   "source": [
    "# Week 3 Dataset Analysis\n",
    "\n",
    "## Question: How many features remain after applying the following pipeline to the feature matrix?\n",
    "\n",
    "**Answer: 4 features remain after applying the pipeline**\n",
    "\n",
    "The pipeline consists of:\n",
    "1. SimpleImputer (strategy='mean') on Features 1-4 \n",
    "2. StandardScaler on Features 1-4\n",
    "3. OrdinalEncoder on Feature 5\n",
    "4. FeatureUnion to combine the outputs\n",
    "5. VarianceThreshold (threshold=0.1) for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b4204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using scikit-learn version: 1.7.2\n",
      "Dataset shape: (748, 6)\n",
      "\n",
      "Column names: ['V1', 'V2', 'V3', 'V4', 'V5', 'Target']\n",
      "\n",
      "Data types:\n",
      "V1         object\n",
      "V2         object\n",
      "V3        float64\n",
      "V4        float64\n",
      "V5         object\n",
      "Target     object\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12500.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>?</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    V1    V2       V3    V4        V5 Target\n",
       "0  2.0  50.0  12500.0  98.0  NEGATIVE    YES\n",
       "1  0.0  13.0   3250.0  28.0  NEGATIVE    YES\n",
       "2    ?     ?   4000.0  35.0  NEGATIVE    YES\n",
       "3    ?  20.0   5000.0  45.0  NEGATIVE    YES\n",
       "4  1.0  24.0   6000.0  77.0  NEGATIVE     NO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Using scikit-learn version: {sklearn.__version__}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Week3_GA_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db05e15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (748, 5)\n",
      "Target shape: (748,)\n",
      "\n",
      "Feature columns: ['V1', 'V2', 'V3', 'V4', 'V5']\n",
      "\n",
      "Missing values in features:\n",
      "V1    5\n",
      "V2    5\n",
      "V3    0\n",
      "V4    0\n",
      "V5    0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in V5: ['NEGATIVE']\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data according to the pipeline diagram\n",
    "df_processed = df.copy()\n",
    "df_processed = df_processed.replace('?', np.nan)\n",
    "\n",
    "# Convert numeric columns to proper data types\n",
    "numeric_columns = ['V1', 'V2', 'V3', 'V4']\n",
    "for col in numeric_columns:\n",
    "    df_processed[col] = pd.to_numeric(df_processed[col], errors='coerce')\n",
    "\n",
    "# Separate features from target\n",
    "feature_columns = ['V1', 'V2', 'V3', 'V4', 'V5']\n",
    "X = df_processed[feature_columns].copy()\n",
    "y = df_processed['Target']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Missing values in features:\")\n",
    "print(X.isnull().sum())\n",
    "print(f\"Unique values in V5: {X['V5'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f651a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline created successfully!\n",
      "\n",
      "Pipeline steps:\n",
      "1. preprocessor: ColumnTransformer(transformers=[('numeric',\n",
      "                                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['V1', 'V2', 'V3', 'V4']),\n",
      "                                ('categorical',\n",
      "                                 Pipeline(steps=[('ordinal',\n",
      "                                                  OrdinalEncoder())]),\n",
      "                                 ['V5'])])\n",
      "2. variance_selector: VarianceThreshold(threshold=0.1)\n"
     ]
    }
   ],
   "source": [
    "# Implement the exact pipeline from the diagram\n",
    "# Branch 1: SimpleImputer + StandardScaler for numeric features (V1-V4)\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Branch 2: OrdinalEncoder for categorical feature (V5)\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('ordinal', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Create ColumnTransformer to handle different feature types\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', numeric_pipeline, ['V1', 'V2', 'V3', 'V4']),  # Features 1-4\n",
    "        ('categorical', categorical_pipeline, ['V5'])  # Feature 5\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Add VarianceThreshold for feature selection\n",
    "full_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('variance_selector', VarianceThreshold(threshold=0.1))\n",
    "])\n",
    "\n",
    "print(\"Pipeline created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6988eb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original feature matrix shape: (748, 5)\n",
      "Original features: ['V1', 'V2', 'V3', 'V4', 'V5']\n",
      "\n",
      "After handling V5 missing values:\n",
      "V5 unique values: ['NEGATIVE']\n",
      "Missing values: 10\n",
      "\n",
      "After applying the complete pipeline:\n",
      "Transformed feature matrix shape: (748, 4)\n",
      "Number of features remaining: 4\n"
     ]
    }
   ],
   "source": [
    "# Apply the pipeline to the feature matrix\n",
    "print(\"Original feature matrix shape:\", X.shape)\n",
    "\n",
    "# Handle missing values in V5 for OrdinalEncoder\n",
    "X_for_pipeline = X.copy()\n",
    "most_frequent_v5 = X_for_pipeline['V5'].mode()[0]\n",
    "X_for_pipeline['V5'].fillna(most_frequent_v5, inplace=True)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_transformed = full_pipeline.fit_transform(X_for_pipeline)\n",
    "\n",
    "print(f\"After applying the complete pipeline:\")\n",
    "print(f\"Transformed feature matrix shape: {X_transformed.shape}\")\n",
    "print(f\"Number of features remaining: {X_transformed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059f8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETAILED PIPELINE ANALYSIS\n",
      "============================================================\n",
      "\n",
      "1. After preprocessing (imputation + scaling + encoding):\n",
      "   Shape: (748, 5)\n",
      "   Features: 5\n",
      "\n",
      "2. Variance of each feature after preprocessing:\n",
      "   Feature 0: 1.000000\n",
      "   Feature 1: 1.000000\n",
      "   Feature 2: 1.000000\n",
      "   Feature 3: 1.000000\n",
      "   Feature 4: 0.000000\n",
      "\n",
      "3. After VarianceThreshold (threshold=0.1):\n",
      "   Shape: (748, 4)\n",
      "   Features remaining: 4\n",
      "\n",
      "4. Feature selection results:\n",
      "   Feature 0: KEPT (variance: 1.000000)\n",
      "   Feature 1: KEPT (variance: 1.000000)\n",
      "   Feature 2: KEPT (variance: 1.000000)\n",
      "   Feature 3: KEPT (variance: 1.000000)\n",
      "   Feature 4: REMOVED (variance: 0.000000)\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER: 4 features remain after applying the pipeline\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Detailed pipeline analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"DETAILED PIPELINE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Apply preprocessing only (without variance threshold)\n",
    "preprocessor_only = Pipeline([('preprocessor', preprocessor)])\n",
    "X_after_preprocessing = preprocessor_only.fit_transform(X_for_pipeline)\n",
    "print(f\"After preprocessing: {X_after_preprocessing.shape[1]} features\")\n",
    "\n",
    "# Step 2: Check variance of each feature\n",
    "variances = np.var(X_after_preprocessing, axis=0)\n",
    "print(f\"\\nVariance of each feature:\")\n",
    "for i, var in enumerate(variances):\n",
    "    print(f\"   Feature {i}: {var:.6f}\")\n",
    "\n",
    "# Step 3: Apply variance threshold\n",
    "variance_selector = VarianceThreshold(threshold=0.1)\n",
    "X_after_variance = variance_selector.fit_transform(X_after_preprocessing)\n",
    "print(f\"\\nAfter VarianceThreshold: {X_after_variance.shape[1]} features\")\n",
    "\n",
    "# Show which features were selected\n",
    "selected_features = variance_selector.get_support()\n",
    "print(f\"\\nFeature selection results:\")\n",
    "for i, (selected, var) in enumerate(zip(selected_features, variances)):\n",
    "    status = \"KEPT\" if selected else \"REMOVED\"\n",
    "    print(f\"   Feature {i}: {status} (variance: {var:.6f})\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"FINAL ANSWER: {X_after_variance.shape[1]} features remain\")\n",
    "print(f\"\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43eb5b",
   "metadata": {},
   "source": [
    "## Question 2: What are the two most important features computed by RFE?\n",
    "\n",
    "**Answer: V1 and V3**\n",
    "\n",
    "**Instructions:** Preprocess the data using pipeline shown in the diagram. Use LogisticRegression (with default parameters) for the estimator. Encode target variable via ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fa43701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target encoding:\n",
      "Original target values: ['YES' 'NO']\n",
      "Encoded target values: [0. 1.]\n",
      "Encoding mapping: {'YES': np.float64(1.0), 'NO': np.float64(0.0)}\n"
     ]
    }
   ],
   "source": [
    "# Import additional libraries for RFE and target encoding\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OrdinalEncoder as TargetOrdinalEncoder\n",
    "\n",
    "# Encode target variable using ordinal encoding\n",
    "target_encoder = TargetOrdinalEncoder()\n",
    "y_encoded = target_encoder.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"Target encoding:\")\n",
    "print(f\"Original target values: {y.unique()}\")\n",
    "print(f\"Encoded target values: {np.unique(y_encoded)}\")\n",
    "print(f\"Encoding mapping: {dict(zip(y.unique(), target_encoder.transform(y.unique().reshape(-1, 1)).ravel()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04bafc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after preprocessing: (748, 5)\n",
      "Features available for RFE: 5\n",
      "\n",
      "Shape after RFE: (748, 2)\n",
      "Selected 2 features\n"
     ]
    }
   ],
   "source": [
    "# Apply the preprocessing pipeline (without VarianceThreshold for RFE)\n",
    "# RFE will do its own feature selection\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Transform the data using the preprocessing pipeline\n",
    "X_preprocessed = preprocessing_pipeline.fit_transform(X_for_pipeline)\n",
    "\n",
    "print(f\"Shape after preprocessing: {X_preprocessed.shape}\")\n",
    "print(f\"Features available for RFE: {X_preprocessed.shape[1]}\")\n",
    "\n",
    "# Create LogisticRegression estimator with default parameters\n",
    "estimator = LogisticRegression()\n",
    "\n",
    "# Create RFE to select 2 most important features\n",
    "rfe = RFE(estimator=estimator, n_features_to_select=2)\n",
    "\n",
    "# Fit RFE on the preprocessed data\n",
    "X_rfe = rfe.fit_transform(X_preprocessed, y_encoded)\n",
    "\n",
    "print(f\"\\nShape after RFE: {X_rfe.shape}\")\n",
    "print(f\"Selected {X_rfe.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ad2af5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RFE FEATURE SELECTION RESULTS\n",
      "============================================================\n",
      "Feature selection results:\n",
      "Feature 0 (V1): SELECTED\n",
      "Feature 1 (V2): RANK 3\n",
      "Feature 2 (V3): SELECTED\n",
      "Feature 3 (V4): RANK 2\n",
      "Feature 4 (V5_encoded): RANK 4\n",
      "\n",
      "============================================================\n",
      "TWO MOST IMPORTANT FEATURES BY RFE:\n",
      "1. V1\n",
      "2. V3\n",
      "============================================================\n",
      "\n",
      "Verification:\n",
      "Number of features selected: 2\n",
      "Selected feature indices: [0 2]\n",
      "Feature rankings: [1 3 1 2 4]\n"
     ]
    }
   ],
   "source": [
    "# Analyze RFE results\n",
    "print(\"=\" * 60)\n",
    "print(\"RFE FEATURE SELECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature support (which features were selected)\n",
    "feature_support = rfe.support_\n",
    "feature_ranking = rfe.ranking_\n",
    "\n",
    "# Map back to original feature names\n",
    "# After preprocessing: [V1, V2, V3, V4, V5_encoded]\n",
    "feature_names_after_preprocessing = ['V1', 'V2', 'V3', 'V4', 'V5_encoded']\n",
    "\n",
    "print(\"Feature selection results:\")\n",
    "selected_features = []\n",
    "for i, (name, selected, rank) in enumerate(zip(feature_names_after_preprocessing, feature_support, feature_ranking)):\n",
    "    status = \"SELECTED\" if selected else f\"RANK {rank}\"\n",
    "    print(f\"Feature {i} ({name}): {status}\")\n",
    "    if selected:\n",
    "        selected_features.append(name)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"TWO MOST IMPORTANT FEATURES BY RFE:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"{i}. {feature}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Verify the results\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Number of features selected: {len(selected_features)}\")\n",
    "print(f\"Selected feature indices: {np.where(feature_support)[0]}\")\n",
    "print(f\"Feature rankings: {feature_ranking}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd5ebf",
   "metadata": {},
   "source": [
    "## Question 3: What are the indices of two most important features computed by SFS (forward)?\n",
    "\n",
    "**Answer: Indices [1, 3] (Features V2 and V4)**\n",
    "\n",
    "**Instructions:** Preprocess the data using pipeline shown in the diagram. Use LogisticRegression (with default parameters) for the estimator. Encode target variable via ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60668235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed data with shape: (748, 5)\n",
      "Target encoding already done: [0. 1.]\n",
      "\n",
      "Shape after SFS: (748, 2)\n",
      "Selected 2 features\n"
     ]
    }
   ],
   "source": [
    "# Import SequentialFeatureSelector for SFS\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Use the same preprocessed data from the previous question\n",
    "print(f\"Using preprocessed data with shape: {X_preprocessed.shape}\")\n",
    "print(f\"Target encoding already done: {np.unique(y_encoded)}\")\n",
    "\n",
    "# Create LogisticRegression estimator with default parameters\n",
    "estimator_sfs = LogisticRegression()\n",
    "\n",
    "# Create Sequential Feature Selector (forward direction)\n",
    "# n_features_to_select=2 to get the two most important features\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=estimator_sfs, \n",
    "    n_features_to_select=2, \n",
    "    direction='forward'\n",
    ")\n",
    "\n",
    "# Fit SFS on the preprocessed data\n",
    "X_sfs = sfs.fit_transform(X_preprocessed, y_encoded)\n",
    "\n",
    "print(f\"\\nShape after SFS: {X_sfs.shape}\")\n",
    "print(f\"Selected {X_sfs.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "934d7dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SFS (FORWARD) FEATURE SELECTION RESULTS\n",
      "============================================================\n",
      "Feature selection results:\n",
      "Index 0 (V1): NOT SELECTED\n",
      "Index 1 (V2): SELECTED\n",
      "Index 2 (V3): NOT SELECTED\n",
      "Index 3 (V4): SELECTED\n",
      "Index 4 (V5_encoded): NOT SELECTED\n",
      "\n",
      "============================================================\n",
      "TWO MOST IMPORTANT FEATURES BY SFS (FORWARD):\n",
      "1. Index 1 (V2)\n",
      "2. Index 3 (V4)\n",
      "\n",
      "ANSWER - Selected feature indices: [1, 3]\n",
      "============================================================\n",
      "\n",
      "Verification:\n",
      "Number of features selected: 2\n",
      "Selected indices from get_support(): [1 3]\n",
      "Feature support array: [False  True False  True False]\n",
      "\n",
      "Feature selection mapping:\n",
      "- Feature 0 (V1): ✗\n",
      "- Feature 1 (V2): ✓\n",
      "- Feature 2 (V3): ✗\n",
      "- Feature 3 (V4): ✓\n",
      "- Feature 4 (V5): ✗\n"
     ]
    }
   ],
   "source": [
    "# Analyze SFS results\n",
    "print(\"=\" * 60)\n",
    "print(\"SFS (FORWARD) FEATURE SELECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature support (which features were selected)\n",
    "feature_support_sfs = sfs.get_support()\n",
    "selected_indices = np.where(feature_support_sfs)[0]\n",
    "\n",
    "# Map back to original feature names\n",
    "feature_names_after_preprocessing = ['V1', 'V2', 'V3', 'V4', 'V5_encoded']\n",
    "\n",
    "print(\"Feature selection results:\")\n",
    "selected_features_sfs = []\n",
    "selected_feature_indices = []\n",
    "\n",
    "for i, (name, selected) in enumerate(zip(feature_names_after_preprocessing, feature_support_sfs)):\n",
    "    status = \"SELECTED\" if selected else \"NOT SELECTED\"\n",
    "    print(f\"Index {i} ({name}): {status}\")\n",
    "    if selected:\n",
    "        selected_features_sfs.append(name)\n",
    "        selected_feature_indices.append(i)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"TWO MOST IMPORTANT FEATURES BY SFS (FORWARD):\")\n",
    "for idx, (feature_idx, feature_name) in enumerate(zip(selected_feature_indices, selected_features_sfs)):\n",
    "    print(f\"{idx+1}. Index {feature_idx} ({feature_name})\")\n",
    "\n",
    "print(f\"\\nANSWER - Selected feature indices: {selected_feature_indices}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Additional verification\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Number of features selected: {len(selected_feature_indices)}\")\n",
    "print(f\"Selected indices from get_support(): {selected_indices}\")\n",
    "print(f\"Feature support array: {feature_support_sfs}\")\n",
    "\n",
    "# Show the selection process\n",
    "print(f\"\\nFeature selection mapping:\")\n",
    "print(f\"- Feature 0 (V1): {'✓' if 0 in selected_feature_indices else '✗'}\")\n",
    "print(f\"- Feature 1 (V2): {'✓' if 1 in selected_feature_indices else '✗'}\")\n",
    "print(f\"- Feature 2 (V3): {'✓' if 2 in selected_feature_indices else '✗'}\")\n",
    "print(f\"- Feature 3 (V4): {'✓' if 3 in selected_feature_indices else '✗'}\")\n",
    "print(f\"- Feature 4 (V5): {'✓' if 4 in selected_feature_indices else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2033e0",
   "metadata": {},
   "source": [
    "## Question 4: What are the indices of two most important features computed by SFS (backward)?\n",
    "\n",
    "**Answer: Indices [2, 3] (Features V3 and V4)**\n",
    "\n",
    "**Instructions:** Preprocess the data using pipeline shown in the diagram. Use LogisticRegression (with default parameters) for the estimator. Encode target variable via ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3b08191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using preprocessed data with shape: (748, 5)\n",
      "Target encoding already done: [0. 1.]\n",
      "\n",
      "Shape after SFS (backward): (748, 2)\n",
      "Selected 2 features\n"
     ]
    }
   ],
   "source": [
    "# Use the same preprocessed data from previous questions\n",
    "print(f\"Using preprocessed data with shape: {X_preprocessed.shape}\")\n",
    "print(f\"Target encoding already done: {np.unique(y_encoded)}\")\n",
    "\n",
    "# Create LogisticRegression estimator with default parameters\n",
    "estimator_sfs_backward = LogisticRegression()\n",
    "\n",
    "# Create Sequential Feature Selector (backward direction)\n",
    "# n_features_to_select=2 to get the two most important features\n",
    "sfs_backward = SequentialFeatureSelector(\n",
    "    estimator=estimator_sfs_backward, \n",
    "    n_features_to_select=2, \n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# Fit SFS backward on the preprocessed data\n",
    "X_sfs_backward = sfs_backward.fit_transform(X_preprocessed, y_encoded)\n",
    "\n",
    "print(f\"\\nShape after SFS (backward): {X_sfs_backward.shape}\")\n",
    "print(f\"Selected {X_sfs_backward.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5603233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SFS (BACKWARD) FEATURE SELECTION RESULTS\n",
      "============================================================\n",
      "Feature selection results:\n",
      "Index 0 (V1): NOT SELECTED\n",
      "Index 1 (V2): NOT SELECTED\n",
      "Index 2 (V3): SELECTED\n",
      "Index 3 (V4): SELECTED\n",
      "Index 4 (V5_encoded): NOT SELECTED\n",
      "\n",
      "============================================================\n",
      "TWO MOST IMPORTANT FEATURES BY SFS (BACKWARD):\n",
      "1. Index 2 (V3)\n",
      "2. Index 3 (V4)\n",
      "\n",
      "ANSWER - Selected feature indices: [2, 3]\n",
      "============================================================\n",
      "\n",
      "Verification:\n",
      "Number of features selected: 2\n",
      "Selected indices from get_support(): [2 3]\n",
      "Feature support array: [False False  True  True False]\n",
      "\n",
      "Feature selection mapping:\n",
      "- Feature 0 (V1): ✗\n",
      "- Feature 1 (V2): ✗\n",
      "- Feature 2 (V3): ✓\n",
      "- Feature 3 (V4): ✓\n",
      "- Feature 4 (V5): ✗\n",
      "\n",
      "Comparison with SFS Forward:\n",
      "SFS Forward selected indices: [1, 3]\n",
      "SFS Backward selected indices: [2, 3]\n",
      "Same selection: False\n"
     ]
    }
   ],
   "source": [
    "# Analyze SFS (backward) results\n",
    "print(\"=\" * 60)\n",
    "print(\"SFS (BACKWARD) FEATURE SELECTION RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Get feature support (which features were selected)\n",
    "feature_support_sfs_backward = sfs_backward.get_support()\n",
    "selected_indices_backward = np.where(feature_support_sfs_backward)[0]\n",
    "\n",
    "# Map back to original feature names\n",
    "feature_names_after_preprocessing = ['V1', 'V2', 'V3', 'V4', 'V5_encoded']\n",
    "\n",
    "print(\"Feature selection results:\")\n",
    "selected_features_sfs_backward = []\n",
    "selected_feature_indices_backward = []\n",
    "\n",
    "for i, (name, selected) in enumerate(zip(feature_names_after_preprocessing, feature_support_sfs_backward)):\n",
    "    status = \"SELECTED\" if selected else \"NOT SELECTED\"\n",
    "    print(f\"Index {i} ({name}): {status}\")\n",
    "    if selected:\n",
    "        selected_features_sfs_backward.append(name)\n",
    "        selected_feature_indices_backward.append(i)\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"TWO MOST IMPORTANT FEATURES BY SFS (BACKWARD):\")\n",
    "for idx, (feature_idx, feature_name) in enumerate(zip(selected_feature_indices_backward, selected_features_sfs_backward)):\n",
    "    print(f\"{idx+1}. Index {feature_idx} ({feature_name})\")\n",
    "\n",
    "print(f\"\\nANSWER - Selected feature indices: {selected_feature_indices_backward}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Additional verification\n",
    "print(f\"\\nVerification:\")\n",
    "print(f\"Number of features selected: {len(selected_feature_indices_backward)}\")\n",
    "print(f\"Selected indices from get_support(): {selected_indices_backward}\")\n",
    "print(f\"Feature support array: {feature_support_sfs_backward}\")\n",
    "\n",
    "# Show the selection process\n",
    "print(f\"\\nFeature selection mapping:\")\n",
    "print(f\"- Feature 0 (V1): {'✓' if 0 in selected_feature_indices_backward else '✗'}\")\n",
    "print(f\"- Feature 1 (V2): {'✓' if 1 in selected_feature_indices_backward else '✗'}\")\n",
    "print(f\"- Feature 2 (V3): {'✓' if 2 in selected_feature_indices_backward else '✗'}\")\n",
    "print(f\"- Feature 3 (V4): {'✓' if 3 in selected_feature_indices_backward else '✗'}\")\n",
    "print(f\"- Feature 4 (V5): {'✓' if 4 in selected_feature_indices_backward else '✗'}\")\n",
    "\n",
    "# Compare with forward SFS results\n",
    "print(f\"\\nComparison with SFS Forward:\")\n",
    "print(f\"SFS Forward selected indices: {selected_feature_indices}\")\n",
    "print(f\"SFS Backward selected indices: {selected_feature_indices_backward}\")\n",
    "print(f\"Same selection: {selected_feature_indices == selected_feature_indices_backward}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
