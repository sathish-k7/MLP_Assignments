{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce93a3d",
   "metadata": {},
   "source": [
    "# Week 1 Dataset Analysis\n",
    "\n",
    "This notebook analyzes the Week1_GA_dataset.csv to answer the given questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51950ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (10000, 12)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Locality</th>\n",
       "      <th>Estimated Value</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Property</th>\n",
       "      <th>Residential</th>\n",
       "      <th>num_rooms</th>\n",
       "      <th>num_bathrooms</th>\n",
       "      <th>carpet_area</th>\n",
       "      <th>property_tax_rate</th>\n",
       "      <th>Face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2009</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>111440.0</td>\n",
       "      <td>185000.0</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Detached House</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>996.0</td>\n",
       "      <td>1.025953</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2009</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>124670.0</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>Two Family</td>\n",
       "      <td>Duplex</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1241.0</td>\n",
       "      <td>1.025953</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2009</td>\n",
       "      <td>Waterbury</td>\n",
       "      <td>55720.0</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Detached House</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>910.0</td>\n",
       "      <td>1.025953</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2009</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>4775276.0</td>\n",
       "      <td>272900.0</td>\n",
       "      <td>Single Family</td>\n",
       "      <td>Detached House</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>971.0</td>\n",
       "      <td>1.025953</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>2009</td>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>112351.0</td>\n",
       "      <td>210000.0</td>\n",
       "      <td>?</td>\n",
       "      <td>Detached House</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1.025953</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Year    Locality  Estimated Value  Sale Price       Property  \\\n",
       "0  2009-01-02  2009   Waterbury         111440.0    185000.0  Single Family   \n",
       "1  2009-01-02  2009  Bridgeport         124670.0    150000.0     Two Family   \n",
       "2  2009-01-02  2009   Waterbury          55720.0    140000.0  Single Family   \n",
       "3  2009-01-02  2009  Bridgeport        4775276.0    272900.0  Single Family   \n",
       "4  2009-01-02  2009  Bridgeport         112351.0    210000.0              ?   \n",
       "\n",
       "      Residential  num_rooms  num_bathrooms  carpet_area  property_tax_rate  \\\n",
       "0  Detached House          3              3        996.0           1.025953   \n",
       "1          Duplex          4              3       1241.0           1.025953   \n",
       "2  Detached House          3              2        910.0           1.025953   \n",
       "3  Detached House          3              1        971.0           1.025953   \n",
       "4  Detached House          3              2       1092.0           1.025953   \n",
       "\n",
       "    Face  \n",
       "0  South  \n",
       "1  South  \n",
       "2  South  \n",
       "3   East  \n",
       "4   East  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Week1_GA_dataset.csv')\n",
    "\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1641a",
   "metadata": {},
   "source": [
    "## Question 1: How many unknown (\"?\") values are present in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80d19f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unknown ('?') values in the dataset: 1823\n",
      "\n",
      "Distribution of '?' values by column:\n",
      "Property: 1823\n"
     ]
    }
   ],
   "source": [
    "# Count unknown values (\"?\") in the dataset\n",
    "unknown_count = (df == '?').sum().sum()\n",
    "print(f\"Number of unknown ('?') values in the dataset: {unknown_count}\")\n",
    "\n",
    "# Show distribution of '?' values across columns\n",
    "unknown_per_column = (df == '?').sum()\n",
    "print(f\"\\nDistribution of '?' values by column:\")\n",
    "for col, count in unknown_per_column.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69373d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED ANALYSIS OF UNKNOWN VALUES ===\n",
      "Method 1 - Count of '?' values: 1823\n",
      "Method 2 - Count of empty strings: 0\n",
      "Method 3 - Original NaN values: 3725\n",
      "\n",
      "=== CHECKING FOR OTHER UNKNOWN VALUE REPRESENTATIONS ===\n",
      "'?': 1823\n",
      "\n",
      "Total unknown values (all representations): 1823\n",
      "\n",
      "After replacing '?' with NaN: 5548\n",
      "\n",
      "=== DATA TYPE ANALYSIS ===\n",
      "Data types:\n",
      "Date                  object\n",
      "Year                   int64\n",
      "Locality              object\n",
      "Estimated Value      float64\n",
      "Sale Price           float64\n",
      "Property              object\n",
      "Residential           object\n",
      "num_rooms              int64\n",
      "num_bathrooms          int64\n",
      "carpet_area          float64\n",
      "property_tax_rate    float64\n",
      "Face                  object\n",
      "dtype: object\n",
      "\n",
      "=== SAMPLE OF UNIQUE VALUES PER COLUMN (first 10) ===\n",
      "Date: ['2009-01-02' '2009-01-03' '2009-01-04' '2009-01-05' '2009-01-08'\n",
      " '2009-01-09' '2009-01-10' '2009-01-11' '2009-01-12' '2009-01-16']\n",
      "Year: [2009 2010 2011 2012 2013 2014 2015 2016 2017 2018]\n",
      "Locality: ['Waterbury' 'Bridgeport' 'Greenwich' 'Norwalk' nan 'Fairfield'\n",
      " 'West Hartford' 'Stamford']\n",
      "Estimated Value: [ 111440.  124670.   55720. 4775276.  112351. 2868880.  571060.  592760.\n",
      "  603540.  137901.]\n",
      "Sale Price: [ 185000.  150000.  140000.  272900.  210000. 3300000. 1000000.  920000.\n",
      " 1680000.  245000.]\n",
      "Property: ['Single Family' 'Two Family' '?' 'Three Family' 'Four Family']\n",
      "Residential: ['Detached House' 'Duplex' 'Triplex' 'Fourplex']\n",
      "num_rooms: [3 4 6 8]\n",
      "num_bathrooms: [3 2 1 4 5 6 8 7]\n",
      "carpet_area: [ 996. 1241.  910.  971. 1092. 1039.   nan  937.  956.  926.]\n",
      "property_tax_rate: [1.025953 1.025846 1.025033 1.021958 1.020333 1.350819 1.340225 1.348259\n",
      " 1.388283 1.422308]\n",
      "Face: ['South' 'East' 'North' 'West']\n"
     ]
    }
   ],
   "source": [
    "# Let's do a more thorough investigation of Question 1\n",
    "print(\"=== DETAILED ANALYSIS OF UNKNOWN VALUES ===\")\n",
    "\n",
    "# Method 1: Count '?' values\n",
    "question_marks = (df == '?').sum().sum()\n",
    "print(f\"Method 1 - Count of '?' values: {question_marks}\")\n",
    "\n",
    "# Method 2: Count empty strings\n",
    "empty_strings = (df == '').sum().sum()\n",
    "print(f\"Method 2 - Count of empty strings: {empty_strings}\")\n",
    "\n",
    "# Method 3: Count original NaN values (before replacement)\n",
    "original_nans = df.isnull().sum().sum()\n",
    "print(f\"Method 3 - Original NaN values: {original_nans}\")\n",
    "\n",
    "# Method 4: Check for other unknown representations\n",
    "print(\"\\n=== CHECKING FOR OTHER UNKNOWN VALUE REPRESENTATIONS ===\")\n",
    "# Check for various representations of missing values\n",
    "unknown_representations = ['?', '', 'Unknown', 'unknown', 'UNKNOWN', 'N/A', 'NA', 'null', 'NULL', 'None']\n",
    "\n",
    "total_unknown = 0\n",
    "for unknown_val in unknown_representations:\n",
    "    count = (df == unknown_val).sum().sum()\n",
    "    if count > 0:\n",
    "        print(f\"'{unknown_val}': {count}\")\n",
    "        total_unknown += count\n",
    "\n",
    "print(f\"\\nTotal unknown values (all representations): {total_unknown}\")\n",
    "\n",
    "# Method 5: Let's also check what the total missing values are after replacement\n",
    "after_replacement_nans = df_cleaned.isnull().sum().sum()\n",
    "print(f\"\\nAfter replacing '?' with NaN: {after_replacement_nans}\")\n",
    "\n",
    "# Let's also look at the data types and see if there are any issues\n",
    "print(\"\\n=== DATA TYPE ANALYSIS ===\")\n",
    "print(\"Data types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check unique values in each column to see if there are other unknown patterns\n",
    "print(\"\\n=== SAMPLE OF UNIQUE VALUES PER COLUMN (first 10) ===\")\n",
    "for col in df.columns:\n",
    "    unique_vals = df[col].unique()\n",
    "    print(f\"{col}: {unique_vals[:10] if len(unique_vals) > 10 else unique_vals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a371f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== QUESTION 1 CLARIFICATION ===\n",
      "The question asks: 'How many unknown (\"?\") values are present in the dataset?'\n",
      "\n",
      "There are two ways to interpret this:\n",
      "1. Strictly '?' values only: 1823\n",
      "2. All unknown values (including original NaN + '?'): 5548\n",
      "\n",
      "Original dataset had:\n",
      "- NaN values: 3725\n",
      "- '?' values: 1823\n",
      "- Total unknown: 5548\n",
      "\n",
      "After replacing '?' with NaN:\n",
      "- Total NaN values: 5548\n",
      "\n",
      "ANSWER: If we interpret 'unknown values' as ALL missing/unknown data,\n",
      "the answer is 5548\n"
     ]
    }
   ],
   "source": [
    "# CLARIFICATION FOR QUESTION 1\n",
    "print(\"=== QUESTION 1 CLARIFICATION ===\")\n",
    "print(\"The question asks: 'How many unknown (\\\"?\\\") values are present in the dataset?'\")\n",
    "print()\n",
    "print(\"There are two ways to interpret this:\")\n",
    "print(f\"1. Strictly '?' values only: {(df == '?').sum().sum()}\")\n",
    "print(f\"2. All unknown values (including original NaN + '?'): {df_cleaned.isnull().sum().sum()}\")\n",
    "print()\n",
    "print(\"Original dataset had:\")\n",
    "print(f\"- NaN values: {df.isnull().sum().sum()}\")\n",
    "print(f\"- '?' values: {(df == '?').sum().sum()}\")\n",
    "print(f\"- Total unknown: {df.isnull().sum().sum() + (df == '?').sum().sum()}\")\n",
    "print()\n",
    "print(\"After replacing '?' with NaN:\")\n",
    "print(f\"- Total NaN values: {df_cleaned.isnull().sum().sum()}\")\n",
    "print()\n",
    "print(\"ANSWER: If we interpret 'unknown values' as ALL missing/unknown data,\")\n",
    "print(f\"the answer is {df_cleaned.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016b79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "QUESTION 1 FINAL ANSWER\n",
      "============================================================\n",
      "Question: How many unknown (\"?\") values are present in the dataset?\n",
      "Instruction: Remove/Delete unknown (\"?\") values to make it null value\n",
      "Note: Remove/Delete means it will show NAN in place of \"?\"\n",
      "\n",
      "Original dataset shape: (10000, 12)\n",
      "Literal '?' values in dataset: 1823\n",
      "Original NaN values in dataset: 3725\n",
      "Total unknown values (NaN + '?'): 5548\n",
      "After replacing '?' with NaN: 5548\n",
      "\n",
      "============================================================\n",
      "FINAL ANSWER:\n",
      "Number of unknown values in the dataset: 5548\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# DEFINITIVE ANSWER FOR QUESTION 1\n",
    "print(\"=\"*60)\n",
    "print(\"QUESTION 1 FINAL ANSWER\")\n",
    "print(\"=\"*60)\n",
    "print('Question: How many unknown (\"?\") values are present in the dataset?')\n",
    "print('Instruction: Remove/Delete unknown (\"?\") values to make it null value')\n",
    "print('Note: Remove/Delete means it will show NAN in place of \"?\"')\n",
    "print()\n",
    "\n",
    "# Step 1: Load fresh dataset to ensure clean analysis\n",
    "df_fresh = pd.read_csv('Week1_GA_dataset.csv')\n",
    "print(f\"Original dataset shape: {df_fresh.shape}\")\n",
    "\n",
    "# Step 2: Count literal \"?\" values\n",
    "literal_question_marks = (df_fresh == '?').sum().sum()\n",
    "print(f\"Literal '?' values in dataset: {literal_question_marks}\")\n",
    "\n",
    "# Step 3: Count original NaN values  \n",
    "original_nan_count = df_fresh.isnull().sum().sum()\n",
    "print(f\"Original NaN values in dataset: {original_nan_count}\")\n",
    "\n",
    "# Step 4: Total unknown values (this is what the question is asking for)\n",
    "total_unknown_values = literal_question_marks + original_nan_count\n",
    "print(f\"Total unknown values (NaN + '?'): {total_unknown_values}\")\n",
    "\n",
    "# Step 5: Replace \"?\" with NaN as instructed\n",
    "df_processed = df_fresh.replace('?', pd.NA)\n",
    "final_nan_count = df_processed.isnull().sum().sum()\n",
    "print(f\"After replacing '?' with NaN: {final_nan_count}\")\n",
    "\n",
    "print()\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL ANSWER:\")\n",
    "print(f\"Number of unknown values in the dataset: {total_unknown_values}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42177a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values after replacement: 5548\n",
      "Number of '?' values remaining: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' with NaN values\n",
    "df_cleaned = df.replace('?', np.nan)\n",
    "\n",
    "# Verify the replacement\n",
    "print(f\"Number of NaN values after replacement: {df_cleaned.isnull().sum().sum()}\")\n",
    "print(f\"Number of '?' values remaining: {(df_cleaned == '?').sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b7d37",
   "metadata": {},
   "source": [
    "## Question 2: What is the shape of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef36220e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the original dataset: (10000, 12)\n",
      "Shape of the cleaned dataset: (10000, 12)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the original dataset\n",
    "print(f\"Shape of the original dataset: {df.shape}\")\n",
    "print(f\"Shape of the cleaned dataset: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58938a2",
   "metadata": {},
   "source": [
    "## Question 3: What is the value present at the 692nd indexed row and 0th indexed column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe6e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at row 692, column 0: 2009-11-16\n",
      "Column 0 name: Date\n"
     ]
    }
   ],
   "source": [
    "# Get value at row 692, column 0\n",
    "value_692_0 = df_cleaned.iloc[692, 0]\n",
    "print(f\"Value at row 692, column 0: {value_692_0}\")\n",
    "\n",
    "# Show the column name for reference\n",
    "print(f\"Column 0 name: {df_cleaned.columns[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b1d4cf",
   "metadata": {},
   "source": [
    "## Question 4: What is the value present at the 546th indexed row and 7th indexed column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71aef338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value at row 546, column 7: 3\n",
      "Column 7 name: num_rooms\n"
     ]
    }
   ],
   "source": [
    "# Get value at row 546, column 7\n",
    "value_546_7 = df_cleaned.iloc[546, 7]\n",
    "print(f\"Value at row 546, column 7: {value_546_7}\")\n",
    "\n",
    "# Show the column name for reference\n",
    "print(f\"Column 7 name: {df_cleaned.columns[7]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a66e45",
   "metadata": {},
   "source": [
    "## Question 5: What are the unique values present in the Locality feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af6e16b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Locality feature:\n",
      "['Bridgeport', 'Fairfield', 'Greenwich', 'Norwalk', 'Stamford', 'Waterbury', 'West Hartford']\n",
      "\n",
      "Number of unique localities: 7\n"
     ]
    }
   ],
   "source": [
    "# Get unique values in Locality column (excluding NaN)\n",
    "unique_localities = df_cleaned['Locality'].dropna().unique()\n",
    "print(f\"Unique values in Locality feature:\")\n",
    "print(sorted(unique_localities))\n",
    "print(f\"\\nNumber of unique localities: {len(unique_localities)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903679fa",
   "metadata": {},
   "source": [
    "## Question 6: Which features have missing (NaN) values in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad27c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features with missing (NaN) values:\n",
      "Locality: 1253 missing values\n",
      "Estimated Value: 1243 missing values\n",
      "Property: 1823 missing values\n",
      "carpet_area: 1229 missing values\n",
      "\n",
      "Features with missing values: ['Locality', 'Estimated Value', 'Property', 'carpet_area']\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df_cleaned.isnull().sum()\n",
    "features_with_missing = missing_values[missing_values > 0]\n",
    "\n",
    "print(\"Features with missing (NaN) values:\")\n",
    "for feature, count in features_with_missing.items():\n",
    "    print(f\"{feature}: {count} missing values\")\n",
    "\n",
    "print(f\"\\nFeatures with missing values: {list(features_with_missing.index)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc17a3b",
   "metadata": {},
   "source": [
    "## Question 7: Which feature has the most missing (NaN) values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4f8ab08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature with most missing values: Property\n",
      "Number of missing values: 1823\n",
      "\n",
      "Top features by missing value count:\n",
      "Property           1823\n",
      "Locality           1253\n",
      "Estimated Value    1243\n",
      "carpet_area        1229\n",
      "Date                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find the feature with the most missing values\n",
    "feature_most_missing = missing_values.idxmax()\n",
    "max_missing_count = missing_values.max()\n",
    "\n",
    "print(f\"Feature with most missing values: {feature_most_missing}\")\n",
    "print(f\"Number of missing values: {max_missing_count}\")\n",
    "\n",
    "# Show top features by missing value count\n",
    "print(f\"\\nTop features by missing value count:\")\n",
    "print(missing_values.sort_values(ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658ddcfe",
   "metadata": {},
   "source": [
    "## Question 8: Drop samples with missing values strictly greater than 2. How many samples remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5329d27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of missing values per row:\n",
      "0    5449\n",
      "1    3637\n",
      "2     831\n",
      "3      83\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Original dataset size: 10000\n",
      "Samples remaining after dropping rows with >2 missing values: 9917\n",
      "Samples dropped: 83\n"
     ]
    }
   ],
   "source": [
    "# Count missing values per row\n",
    "missing_per_row = df_cleaned.isnull().sum(axis=1)\n",
    "\n",
    "# Show distribution of missing values per row\n",
    "print(\"Distribution of missing values per row:\")\n",
    "print(missing_per_row.value_counts().sort_index())\n",
    "\n",
    "# Drop rows with missing values > 2\n",
    "df_filtered = df_cleaned[missing_per_row <= 2]\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df_cleaned)}\")\n",
    "print(f\"Samples remaining after dropping rows with >2 missing values: {len(df_filtered)}\")\n",
    "print(f\"Samples dropped: {len(df_cleaned) - len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c7b2b",
   "metadata": {},
   "source": [
    "## Question 9: Drop all samples with missing values. How many samples remain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c41e5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 10000\n",
      "Samples remaining after dropping all rows with missing values: 5449\n",
      "Samples dropped: 4551\n",
      "\n",
      "Missing values in final dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop all rows with any missing values\n",
    "df_no_missing = df_cleaned.dropna()\n",
    "\n",
    "print(f\"Original dataset size: {len(df_cleaned)}\")\n",
    "print(f\"Samples remaining after dropping all rows with missing values: {len(df_no_missing)}\")\n",
    "print(f\"Samples dropped: {len(df_cleaned) - len(df_no_missing)}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nMissing values in final dataset: {df_no_missing.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ce86a",
   "metadata": {},
   "source": [
    "## Summary of All Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286d9751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL ANSWERS ===\n",
      "1. Number of unknown ('?') values: 1823\n",
      "2. Shape of dataset: (10000, 12)\n",
      "3. Value at [692,0]: 2009-11-16\n",
      "4. Value at [546,7]: 3\n",
      "5. Unique localities: ['Bridgeport', 'Fairfield', 'Greenwich', 'Norwalk', 'Stamford', 'Waterbury', 'West Hartford']\n",
      "6. Features with missing values: ['Locality', 'Estimated Value', 'Property', 'carpet_area']\n",
      "7. Feature with most missing values: Property\n",
      "8. Samples remaining after dropping rows with >2 missing: 9917\n",
      "9. Samples remaining after dropping all missing: 5449\n"
     ]
    }
   ],
   "source": [
    "print(\"=== FINAL ANSWERS ===\")\n",
    "print(f\"1. Number of unknown ('?') values: {unknown_count}\")\n",
    "print(f\"2. Shape of dataset: {df.shape}\")\n",
    "print(f\"3. Value at [692,0]: {value_692_0}\")\n",
    "print(f\"4. Value at [546,7]: {value_546_7}\")\n",
    "print(f\"5. Unique localities: {sorted(unique_localities)}\")\n",
    "print(f\"6. Features with missing values: {list(features_with_missing.index)}\")\n",
    "print(f\"7. Feature with most missing values: {feature_most_missing}\")\n",
    "print(f\"8. Samples remaining after dropping rows with >2 missing: {len(df_filtered)}\")\n",
    "print(f\"9. Samples remaining after dropping all missing: {len(df_no_missing)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
